# learning

強力なコアソフトウェアエンジニアリングスキルを構築しつつ、[隣接技術](http://www.effectiveengineer.com/blog/master-adjacent-disciplines)の知識も[毎日少しずつ](https://jamesclear.com/continuous-improvement)広げていくために学んだことの記録です。

**更新頻度**：月1回 | **現在の注力分野**：データベース
**今後取りたい資格**：基本情報技術者
<!-- チェックを付けるときは✅に変える -->


## コアスキル

> どんなソフトウェア業務にも応用できる汎用的なスキル

### Pythonプログラミング

|教材|進捗|
|---|---|
|[Datacamp: 効率的なPythonコードの記述](https://www.datacamp.com/courses/writing-efficient-python-code)|⬜|
|[Datacamp: Pythonで関数を書く](https://www.datacamp.com/courses/writing-functions-in-python)|⬜|
|[Datacamp: Pythonのオブジェクト指向プログラミング](https://www.datacamp.com/courses/object-oriented-programming-in-python)|⬜|
|[Datacamp: Pythonの中級オブジェクト指向プログラミング](https://www.datacamp.com/courses/intermediate-object-oriented-programming-in-python)|⬜|
|[Datacamp: Pythonでデータをインポート（パート1）](https://www.datacamp.com/courses/importing-data-in-python-part-1)|⬜|
|[Datacamp: Pythonでデータをインポート（パート2）](https://www.datacamp.com/courses/importing-data-in-python-part-2)|⬜|
|[Datacamp: データサイエンスのための中級Python](https://www.datacamp.com/courses/intermediate-python-for-data-science)|⬜|
|[Datacamp: Pythonデータサイエンストゥールボックス（パート1）](https://www.datacamp.com/courses/python-data-science-toolbox-part-1)|⬜|
|[Datacamp: Pythonデータサイエンストゥールボックス（パート2）](https://www.datacamp.com/courses/python-data-science-toolbox-part-2)|⬜|
|[Datacamp: Pythonパッケージ開発](https://www.datacamp.com/courses/developing-python-packages)|⬜|
|[Datacamp: Condaの基礎](https://www.datacamp.com/courses/conda-essentials)|⬜|
|[Youtube: チュートリアル: Sebastian Witowski - モダンPython開発者ツールキット](https://www.youtube.com/watch?v=WkUBx3g2QfQ&feature=youtu.be)|⬜|
|[Datacamp: Pythonで日付と時刻を扱う](https://www.datacamp.com/courses/working-with-dates-and-times-in-python)|⬜|
|[Datacamp: Pythonでコマンドライン自動化](https://www.datacamp.com/courses/command-line-automation-in-python)|⬜|
|[書籍: Python 201](https://leanpub.com/python201)|⬜|
|[書籍: Writing Idiomatic Python 3](https://www.amazon.com/Writing-Idiomatic-Python-Jeff-Knupp-ebook/dp/B00B5VXMRG)|⬜|
|[記事: Pythonの多様なコマンドラインユーティリティ](https://www.pythonmorsels.com/cli-tools/)|⬜|
|[記事: プログラマーのためのUnicode入門](https://www.reedbeta.com/blog/programmers-intro-to-unicode/)|⬜|
|[記事: ユーザー満足度を最大化するための文字列型の公開](https://stephantul.github.io/python/typing/2025/03/07/externalized-types/)|⬜|

### テスト & プロファイリング

|教材|進捗|
|---|---|
|[Datacamp: Pythonでデータサイエンスのための単体テスト](https://www.datacamp.com/courses/unit-testing-for-data-science-in-python)|⬜|
|[書籍: テスト駆動開発とPython](http://chimera.labs.oreilly.com/books/1234000000754/index.html)|⬜|
|[記事: Pythonのメモリプロファイリング入門](https://www.datacamp.com/tutorial/memory-profiling-python)|⬜|
|[記事: memory_profilerでPythonコードをプロファイリング](https://www.wrighters.io/profiling-python-code-with-memory_profiler/)|⬜|
|[記事: "memory_profiler"でPythonコードのメモリ使用量をプロファイルする方法](https://coderzcolumn.com/tutorials/python/how-to-profile-memory-usage-in-python-using-memory-profiler)|⬜|
|[Youtube: Docker内でdebugpyとVSCodeを使ってPythonデバッグ](https://www.youtube.com/watch?v=ywfsLKRLmf4)|⬜|
|[記事: Starletteアプリの並行処理（例：FastAPI / FastHTML）](https://hamel.dev/notes/fasthtml/concurrency.html#fnref1)|⬜|


### データ構造とアルゴリズム

|教材|進捗|
|---|---|
|[書籍: Grokking Algorithms](https://www.manning.com/books/grokking-algorithms)|⬜|
|[書籍: The Tech Resume Inside Out](https://thetechresume.com)|⬜|
|[Neetcode: 初心者のためのアルゴリズムとデータ構造](https://neetcode.io/courses/dsa-for-beginners/0)|⬜|
|[Neetcode: 上級アルゴリズム](https://neetcode.io/courses/advanced-algorithms/0) `1/7`|⬜|
|[Udacity: データ構造とアルゴリズム入門](https://www.udacity.com/course/technical-interview--ud513)|⬜|
|[Youtube: スライディングウィンドウ手法 - アルゴリズム的メンタルモデル](https://www.youtube.com/watch?v=MK-NZ4hN7rs) `36:44`|⬜|


### Linux & コマンドライン

|教材|進捗|
|---|---|
|[Datacamp: データサイエンスのためのシェル入門](https://www.datacamp.com/courses/introduction-to-shell-for-data-science)|⬜|
|[Datacamp: Bashスクリプト入門](https://www.datacamp.com/courses/introduction-to-bash-scripting)|⬜|
|[Datacamp: シェルでのデータ処理](https://www.datacamp.com/courses/data-processing-in-shell)|⬜|
|[MIT: Missing Semester](https://www.youtube.com/playlist?list=PLyzOVJj3bHQuloKGG59rS43e29ro7I57J)|⬜|
|[Udacity: Linuxコマンドライン基礎](https://www.udacity.com/course/linux-command-line-basics--ud595)|⬜|
|[Udacity: シェルワークショップ](https://www.udacity.com/course/shell-workshop--ud206)|⬜|
|[Udacity: Linuxウェブサーバーの設定](https://www.udacity.com/course/configuring-linux-web-servers--ud299)|⬜|

### バージョン管理

|教材|進捗|
|---|---|
|[Udacity: Gitによるバージョン管理](https://www.udacity.com/course/version-control-with-git--ud123)|⬜|
|[Datacamp: データサイエンスのためのGit入門](https://www.datacamp.com/courses/introduction-to-git-for-data-science)|⬜|
|[Udacity: GitHubとコラボレーション](https://www.udacity.com/course/github-collaboration--ud456)|⬜|
|[Udacity: GitとGitHubの使い方](https://www.udacity.com/course/how-to-use-git-and-github--ud775)|⬜|
|[Youtube: Git Worktreeの使い方 \| 複数のGitブランチを同時にチェックアウトする方法](https://youtu.be/s4BTvj1ZVLM)|⬜|
|[Datacamp: 高度なGit](https://www.datacamp.com/courses/advanced-git)|⬜|

### データベース

|教材|進捗|
|---|---|
|[Udacity: リレーショナルデータベース入門](https://www.udacity.com/course/intro-to-relational-databases--ud197)|⬜|
|[Udacity: データベースシステムの概念と設計](https://www.udacity.com/course/database-systems-concepts-and-design--ud150)|⬜|
|[Datacamp: データベース設計](https://www.datacamp.com/courses/database-design)|⬜|
|[Datacamp: Pythonにおけるデータベース入門](https://www.datacamp.com/courses/introduction-to-relational-databases-in-python)|⬜|
|[Datacamp: データサイエンスのためのSQL入門](https://www.datacamp.com/courses/intro-to-sql-for-data-science)|⬜|
|[Datacamp: 中級SQL](https://www.datacamp.com/courses/intermediate-sql)|⬜|
|[Datacamp: SQLでのデータ結合](https://www.datacamp.com/courses/joining-data-in-sql)|⬜|
|[Datacamp: SQLでのデータ操作](https://app.datacamp.com/learn/courses/data-manipulation-in-sql)|⬜|
|[Udacity: データ分析のためのSQL](https://www.udacity.com/course/sql-for-data-analysis--ud198)|⬜|
|[Datacamp: SQLによる探索的データ分析](https://www.datacamp.com/courses/sql-for-exploratory-data-analysis)|⬜|
|[Datacamp: SQLを用いた実世界の問題解決](https://www.datacamp.com/courses/applying-sql-to-real-world-problems)|⬜|
|[Datacamp: SQLによるビジネスデータ分析](https://www.datacamp.com/courses/analyzing-business-data-in-sql)|⬜|
|[Datacamp: SQLでのレポーティング](https://www.datacamp.com/courses/reporting-in-sql)|⬜|
|[Datacamp: SQLによるデータ駆動型意思決定](https://www.datacamp.com/courses/data-driven-decision-making-with-sql)|⬜|
|[Datacamp: NoSQLの概念](https://www.datacamp.com/courses/nosql-concepts)|⬜|
|[Datacamp: PythonにおけるMongoDB入門](https://www.datacamp.com/courses/introduction-to-using-mongodb-for-data-science-with-python)|⬜|

### バックエンドエンジニアリング

|教材|進捗|
|---|---|
|[Udacity: 認証と認可: OAuth](https://www.udacity.com/course/authentication-authorization-oauth--ud330)|⬜|
|[Udacity: HTTPとウェブサーバー](https://www.udacity.com/course/http-web-servers--ud303)|⬜|
|[Udacity: クライアントサーバー間通信](https://www.udacity.com/course/client-server-communication--ud897)|⬜|
|[Udacity: RESTful APIの設計](https://www.udacity.com/course/designing-restful-apis--ud388)|⬜|
|[Udacity: ウェブ開発者のためのネットワーキング](https://www.udacity.com/course/networking-for-web-developers--ud256)|⬜|

### プロダクションシステム設計

|教材|進捗|
|---|---|
|[書籍: 機械学習システムの設計](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/)|⬜|
|[Neetcode: 初心者のためのシステム設計](https://neetcode.io/courses/system-design-for-beginners/0)|⬜|
|[Neetcode: システム設計インタビュー](https://neetcode.io/courses/system-design-interview)|⬜|
|[Datacamp: 顧客分析とA/BテストのPython入門](https://www.datacamp.com/courses/customer-analytics-ab-testing-in-python)|⬜|
|[Datacamp: PythonによるA/Bテスト](https://www.datacamp.com/courses/ab-testing-in-python)|⬜|
|[Udacity: A/Bテスト](https://www.udacity.com/course/ab-testing--ud257)|⬜|
|[Datacamp: MLOpsの概念](https://www.datacamp.com/courses/mlops-concepts)|⬜|
|[Datacamp: 機械学習モニタリングの概念](https://www.datacamp.com/courses/machine-learning-monitoring-concepts)|⬜|


### 数学
	
|教材|進捗|
|---|---|
|[Datacamp: Pythonによる確率の基礎](https://www.datacamp.com/courses/foundations-of-probability-in-python)|⬜|
|[Datacamp: 統計学入門](https://www.datacamp.com/courses/introduction-to-statistics)|⬜|
|[Datacamp: Pythonにおける統計学入門](https://www.datacamp.com/courses/introduction-to-statistics-in-python)|⬜|
|[Datacamp: Pythonによる仮説検定](https://www.datacamp.com/courses/hypothesis-testing-in-python)|⬜|
|[Datacamp: Pythonにおける統計的思考（パート1）](https://www.datacamp.com/courses/statistical-thinking-in-python-part-1)|⬜|
|[Datacamp: Pythonにおける統計的思考（パート2）](https://www.datacamp.com/courses/statistical-thinking-in-python-part-2)|⬜|
|[Datacamp: Pythonによる実験計画](https://datacamp.com/courses/experimental-design-in-python)|⬜|
|[Datacamp: Pythonにおける統計インタビュー問題の練習](https://www.datacamp.com/courses/practicing-statistics-interview-questions-in-python)|⬜|
|[edX: Excelを用いたデータ分析のための基礎統計](https://www.edx.org/course/essential-statistics-data-analysis-using-microsoft-dat222x-1)|⬜|
|[Udacity: 推測統計入門](https://www.udacity.com/course/intro-to-inferential-statistics--ud201)|⬜|
|[MIT 18.06 線形代数, 2005年春](https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8)|⬜|
|[Udacity: 固有ベクトルと固有値](https://www.udacity.com/course/eigenvectors-and-eigenvalues--ud104)|⬜|
|[Udacity: 線形代数リフレッシャー](https://www.udacity.com/course/linear-algebra-refresher-course--ud953)|⬜|
|[Youtube: 線形代数の本質](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)|⬜|

## 専門スキル
<hr>

### 従来型機械学習

|教材|進捗|
|---|---|
|[書籍: Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)|⬜|
|[書籍: A Machine Learning Primer](https://www.confetti.ai/assets/ml-primer/ml_primer.pdf)|⬜|
|[書籍: Grokking Machine Learning](https://www.manning.com/books/grokking-machine-learning)|⬜|
|[書籍: The StatQuest Illustrated Guide To Machine Learning](https://www.amazon.com/StatQuest-Illustrated-Guide-Machine-Learning/dp/B0BLM4TLPY)|⬜|
|[Datacamp: Ensemble Methods in Python](https://www.datacamp.com/courses/ensemble-methods-in-python)|⬜|
|[Datacamp: Extreme Gradient Boosting with XGBoost](https://www.datacamp.com/courses/extreme-gradient-boosting-with-xgboost)|⬜|
|[Datacamp: Clustering Methods with SciPy](https://www.datacamp.com/courses/clustering-methods-with-scipy)|⬜|
|[Datacamp: Unsupervised Learning in Python](https://www.datacamp.com/courses/unsupervised-learning-in-python)|⬜|
|[Udacity: セグメンテーションとクラスタリング](https://www.udacity.com/course/segmentation-and-clustering--ud981)|⬜|
|[Datacamp: データサイエンスのためのPython入門](https://www.datacamp.com/courses/intro-to-python-for-data-science)|⬜|
|[edX: Azure HDInsightにおけるSparkを用いた予測分析の実装](https://www.edx.org/course/implementing-predictive-analytics-spark-microsoft-dat202-3x-2)|⬜|
|[Datacamp: scikit-learnによる教師あり学習](https://www.datacamp.com/courses/supervised-learning-with-scikit-learn)|⬜|
|[Datacamp: Pythonにおける木構造モデルを用いた機械学習](https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-python)|⬜|
|[Datacamp: Pythonにおける線形分類器](https://www.datacamp.com/courses/linear-classifiers-in-python)|⬜|
|[Datacamp: Pythonにおけるモデル検証](https://www.datacamp.com/courses/model-validation-in-python)|⬜|
|[Datacamp: Pythonにおけるハイパーパラメータチューニング](https://www.datacamp.com/courses/hyperparameter-tuning-in-python)|⬜|
|[Datacamp: PythonによるHR分析: 従業員の離職予測](https://www.datacamp.com/courses/hr-analytics-in-python-predicting-employee-churn)|⬜|
|[Datacamp: Pythonによる顧客離脱予測](https://www.datacamp.com/courses/predicting-customer-churn-in-python)|⬜|
|[Datacamp: Pythonにおける次元削減](https://www.datacamp.com/courses/dimensionality-reduction-in-python)|⬜|
|[Datacamp: Pythonにおける機械学習のための前処理](https://www.datacamp.com/courses/preprocessing-for-machine-learning-in-python)|⬜|
|[Datacamp: データサイエンスのためのデータ型](https://www.datacamp.com/courses/data-types-for-data-science)|⬜|
|[Datacamp: Pythonにおけるデータクリーニング](https://www.datacamp.com/courses/cleaning-data-in-python)|⬜|
|[Datacamp: Pythonにおける機械学習のための特徴量エンジニアリング](https://www.datacamp.com/courses/feature-engineering-for-machine-learning-in-python)|⬜|
|[Datacamp: PythonによるCTR予測のための機械学習](https://www.datacamp.com/courses/predicting-ctr-with-machine-learning-in-python)|⬜|
|[Datacamp: Pythonによるファイナンシャルコンセプト入門](https://www.datacamp.com/courses/intro-to-financial-concepts-using-python)|⬜|
|[Datacamp: Pythonにおける不正検出](https://www.datacamp.com/courses/fraud-detection-in-python)|⬜|


### 深層学習

|教材|進捗|
|---|---|
|[記事: 勾配降下法最適化アルゴリズムの概要](https://www.ruder.io/optimizing-gradient-descent)|⬜|
|[書籍: Make Your Own Neural Network](https://www.amazon.com/Make-Your-Own-Neural-Network/dp/1530826608)|⬜|
|[Fast.ai: コーダーのための実践的深層学習 (パート 1)](https://course.fast.ai/)|⬜|
|[Fast.ai: コーダーのための実践的深層学習 (パート 2)](https://course.fast.ai/Lessons/part2.html) `9, 13,14,17,18(48:10),19`|⬜|
|[Datacamp: 画像処理のための畳み込みニューラルネットワーク](https://www.datacamp.com/courses/convolutional-neural-networks-for-image-processing)|⬜|
|[Karpathy: ニューラルネットワーク: ゼロからヒーローへ](https://github.com/karpathy/nn-zero-to-hero/)|⬜|
|[記事: ニューラルネットワークにおける重みの初期化: 基礎からカイミングまでの旅](https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79)|⬜|
|[記事: クロスエントロピーに関する私の混乱を解消するための2つのこと](https://chris-said.io/2020/12/26/two-things-that-confused-me-about-cross-entropy/)|⬜|

### 自然言語処理

|教材|進捗|
|---|---|
|[書籍: Transformersによる自然言語処理](https://transformersbook.com/)|⬜|
|[Stanford CS224U: 自然言語理解 \| 2019年春](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)|⬜|
|[Stanford CS224N: 深層学習による自然言語処理 \| 2019年冬](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)|⬜|
|[CMU: 低リソースNLPブートキャンプ 2020](https://www.youtube.com/playlist?list=PL8PYTP1V4I8A1CpCzURXAUa6H4HO7PF2c)|⬜|
|[CMU 多言語NLP 2020](http://demo.clab.cs.cmu.edu/11737fa20/)|⬜|
|[Datacamp: PythonにおけるNLPのための特徴量エンジニアリング](https://www.datacamp.com/courses/feature-engineering-for-nlp-in-python)|⬜|
|[Datacamp: Pythonにおける自然言語処理の基礎](https://www.datacamp.com/courses/natural-language-processing-fundamentals-in-python)|⬜|
|[Datacamp: Pythonにおける正規表現](https://www.datacamp.com/courses/regular-expressions-in-python)|⬜|
|[Datacamp: 言語モデルのためのRNN](https://www.datacamp.com/courses/recurrent-neural-networks-for-language-modeling-in-python)|⬜|
|[Datacamp: Pythonにおける自然言語生成](https://www.datacamp.com/courses/natural-language-generation-in-python)|⬜|
|[Datacamp: Pythonにおけるチャットボットの構築](https://www.datacamp.com/courses/building-chatbots-in-python)|⬜|
|[Datacamp: Pythonにおける感情分析](https://www.datacamp.com/courses/sentiment-analysis-in-python)|⬜|
|[Datacamp: Pythonにおける機械翻訳](https://www.datacamp.com/courses/machine-translation-in-python)|⬜|
|[記事: コロケーションの不合理な効果](https://opensourceconnections.com/blog/2019/05/16/unreasonable-effectiveness-of-collocations/)|⬜|
|[記事: FuzzyWuzzy: Pythonにおけるファジー文字列マッチング](https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/#)|⬜|
|[記事: Transformers: 起源](https://mark-riedl.medium.com/transformers-origins-1db4bdfcb3d1)|⬜|

### 生成AI
<hr>

#### LLM理論

|教材|進捗|
|---|---|
|[書籍: Hands-On Large Language Models: Language Understanding and Generation](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961)|⬜|
|[書籍: AI Engineering: Building Applications with Foundation Models](https://www.amazon.com/AI-Engineering-Building-Applications-Foundation/dp/1098166302)|⬜|
|[書籍: Designing Large Language Model Applications](https://www.oreilly.com/library/view/designing-large-language/9781098150495/)|⬜|
|[書籍: Large Language Models: A Deep Dive: Bridging Theory and Practice](https://www.amazon.com/Large-Language-Models-Bridging-Practice/dp/3031656466)|⬜|
|[Stanford CS236: Deep Generative Models](https://www.youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8) `18 lectures`|2`26:45`|
|[記事: あなたは最先端の位置エンコーディングを設計できたかもしれない](https://fleetwood.dev/posts/you-could-have-designed-SOTA-positional-encoding)|⬜|
|[記事: 数字から決定まで: トークン化がLLMの算術に与える影響](https://huggingface.co/spaces/huggingface/number-tokenization-blog)|⬜|
|[記事: SolidGoldMagikarp (さらに、プロンプト生成)](https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation)|⬜|
|[記事: テキスト生成のためのサンプリング](https://huyenchip.com/2024/01/16/sampling.html)|⬜|
|[記事: Mambaの説明](https://thegradient.pub/mamba-explained/)|⬜|
|[記事: Mambaと状態空間モデルのビジュアルガイド](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state)|⬜|
|[記事: パターンとメッセージ - パート 1 - 欠落した添字](https://mccormickml.com/2025/02/18/patterns-and-messages-part-1-wo-i/)|⬜|
|[記事: テキスト拡散の仕組み](https://pierce.dev/notes/how-text-diffusion-works/)|⬜|
|[記事: 大規模LLMアーキテクチャ比較](https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison)|⬜|
|[DeepLearning.AI: LLMの事前トレーニング](https://www.deeplearning.ai/short-courses/pretraining-llms)|⬜|
|[DeepLearning.AI: 人間のフィードバックからの強化学習](https://www.deeplearning.ai/short-courses/reinforcement-learning-from-human-feedback)|⬜|
|[Karpathy: 大規模言語モデル入門](https://www.youtube.com/watch?v=zjkBMFhNj_g) `1hr`|⬜|
|[Karpathy: GPTトークナイザーの構築](https://www.youtube.com/watch?v=zduSFxRajkE) `2hr13m`|⬜|
|[Karpathy: GPT-2 (124M)の再現](https://www.youtube.com/watch?v=l8pRSuU81PU) `4hr1m`|⬜|
|[Youtube: ハッカーのための言語モデルガイド](https://www.youtube.com/watch?v=jkrNMKz9pWU) `1hr30m`|⬜|
|[Karpathy: ChatGPTのようなLLMのディープダイブ](https://www.youtube.com/watch?v=7xTGNNLPyMI) `3h31m`|⬜|
|[Youtube: GPTの5年間を振り返る Timbers Finbarr](https://www.youtube.com/watch?v=YA0pzBYAV2Q&list=PLKlhhkvvU8-YxMP9hjEYJTJDCaGszrJIh&index=8&t=43s) `55m`|⬜|
|[Youtube: Stanford CS229 I 機械学習 I 大規模言語モデル（LLMs）の構築](https://www.youtube.com/watch?v=9vM4p9NN0Ts) `1h44m`|⬜|
|[Youtube: LLaMAの説明: KV-キャッシュ、ロータリーポジショナルエンコーディング、RMSノルム、グループ化クエリアテンション、SwiGLU](https://www.youtube.com/watch?v=Mn_9W1nCFLo) `1h10m`|⬜|
|[Youtube: CMU Advanced NLP Fall 2024 (7): プロンプトと複雑な推論](https://www.youtube.com/watch?v=1Faf1cTe3T8&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=2)|⬜|
|[Youtube: CMU Advanced NLP Fall 2024 (6): インストラクションチューニング](https://www.youtube.com/watch?v=iWcGS0gCL1E&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=3)|⬜|
|[Youtube: CMU Advanced NLP Fall 2024 (12): ドメイン特化型モデリング: コードと数学](https://www.youtube.com/watch?v=qHNUVpKO2dc&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=4)|⬜|
|[Youtube: CMU Advanced NLP Fall 2024 (15): ツール使用とLLMエージェントの基礎](https://www.youtube.com/watch?v=a3SjRsqV9ZA&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=16)|⬜|
|[Youtube: CMU Advanced NLP Fall 2024 (14): アンサンブルと専門家の混合](https://www.youtube.com/watch?v=E4Rg4qTw4xw&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=15)|⬜|
|[Youtube: 2024年の大規模言語モデル構築ガイド](https://www.youtube.com/watch?v=2-SPH9hIKT8) `1h15m`|⬜|
|[Youtube: AIアプリケーションのためのポストトレーニングアプローチ](https://www.youtube.com/watch?v=grpc-Wyy-Zg) `22m`|⬜|
|[Youtube: 私のLLMの使い方](https://youtu.be/EWvNQjAaOHw) `2h7m`|⬜|
|[Youtube: シンプルな拡散言語モデル](https://youtu.be/WjAUX23vgfg)|⬜|
|[Youtube: Zed Inferred: 拡散言語モデル](https://youtu.be/oot4O9wMohw?list=LL)|⬜|


#### RLHF / RLVR

|教材|進捗|
|---|---|
|[書籍: A Little Bit of Reinforcement Learning from Human Feedback](https://rlhfbook.com/)|⬜|
|[記事: テスト時の計算スケーリング - Hugging FaceのスペースによるHuggingFaceH4のブログ](https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute)|⬜|
|[記事: DeepSeek R1のレシピによるo1の再現と推論LMの未来](https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1)|⬜|
|[記事: The Illustrated DeepSeek-R1](https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1)|⬜|
|[記事: 推論LLMのビジュアルガイド](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms)|⬜|
|[記事: GRPO in DeepSeek-R1](https://hlfshell.ai/posts/grpo/)|⬜|
|[Youtube: DeepSeekがLLMのストーリーをどのように変えるか](https://www.youtube.com/watch?v=0eMzc-WnBfQ)|⬜|
|[Youtube: 推論LLMの紹介](https://www.youtube.com/watch?v=AZhUhGsgz4s) `1hr`|⬜|
|[Youtube: テスト時のスケーリングに関する推測 (o1) `47m`](https://www.youtube.com/watch?v=6PEJ96k1kiw)|⬜|
|[Youtube: DeepSeek-R1: 強化学習を通じてLLMに推論能力を付与](https://youtu.be/XMnxKGVnEUc) `1h19m`|⬜|
|[Youtube: MIT EIセミナー, OpenAIのHyung Won Chung. "教えないで。インセンティブを与えよ。"](https://www.youtube.com/watch?v=kYWUEV_e2ss) `35m`|⬜|
|[Youtube: グループ相対ポリシー最適化 (GRPO) - 数式とコード](https://www.youtube.com/watch?v=Yi1UCrAsf4o) `24m`|⬜|


#### マルチモーダリティ

|教材|進捗|
|---|---|
|[記事: マルチモーダルLLMの理解](https://magazine.sebastianraschka.com/p/understanding-multimodal-llms)|⬜|
|[記事: GPT-4ビジョンの代替案](https://blog.roboflow.com/gpt-4-vision-alternatives/)|⬜|
|[記事: コンピュータ使用エージェント](https://openai.com/index/computer-using-agent/)|⬜|
|[記事: 5分でわかるフローマッチング](https://nrehiew.github.io/blog/flow_matching/)|⬜|
|[記事: LLMは画像、音声、その他をどのように認識するか](https://blog.bytebytego.com/p/how-llms-see-images-audio-and-more)|⬜|
|[Youtube: AI Visions Live \| Merve Noyan \| オープンソースのマルチモーダリティ](https://www.youtube.com/watch?v=_TlhKHTgWjY) `54m`|⬜|
|[DeepLearning.AI: 拡散モデルの仕組み](https://www.deeplearning.ai/short-courses/how-diffusion-models-work/)|⬜|
|[DeepLearning.AI: ビジョンモデルのためのプロンプトエンジニアリング](https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models/)|⬜|
|[DeepLearning.AI: マルチモーダル検索とRAGの構築](https://www.deeplearning.ai/short-courses/building-multimodal-search-and-rag/)|⬜|
|[Pinecone: 画像検索のための埋め込み手法](https://www.pinecone.io/learn/series/image-search/)|0/8|
|[Youtube: Lesson 9A 2022 - Stable Diffusion deep dive](https://youtu.be/0_BBRNYInx8)|⬜|
|[記事: 拡散モデルはオートエンコーダーである](https://sander.ai/2022/01/31/diffusion.html)|⬜|
|[記事: 拡散言語モデル](https://sander.ai/2023/01/09/diffusion-language.html)|⬜|
|[記事: ガイダンス: 拡散モデルのチートコード](https://sander.ai/2022/05/26/guidance.html)|⬜|
|[記事: 拡散に関する視点](https://sander.ai/2023/07/20/perspectives.html)|⬜|
|[記事: 拡散ガイダンスの幾何学](https://sander.ai/2023/08/28/geometry.html)|⬜|
|[記事: 拡散はスペクトル自己回帰である](https://sander.ai/2024/09/02/spectral-autoregression.html)|⬜|
|[記事: 潜在空間における生成モデリング](https://sander.ai/2025/04/15/latents.html)|⬜|
|[記事: 音声AIと音声エージェント - イラスト付き入門](https://voiceaiandvoiceagents.com/)|⬜|
|[Youtube: Sander Dieleman - 反復的洗練を通じた生成モデリング](https://www.youtube.com/watch?v=9BHQvQlsVdE)|⬜|
|[Speech AIモデル: 入門](https://thomwolf.io/blog/speech-ai.html)|⬜|


#### 情報検索 / RAG

|教材|進捗|
|---|---|
|[記事: 検索のための事前学習済みトランスフォーマー言語モデル - パート 1](https://blog.vespa.ai/pretrained-transformer-language-models-for-search-part-1/#) | ⬜        |
| [記事: 検索のための事前学習済みトランスフォーマー言語モデル - パート 2](https://blog.vespa.ai/pretrained-transformer-language-models-for-search-part-2/)  | ⬜        |
| [記事: 検索のための事前学習済みトランスフォーマー言語モデル - パート 3](https://blog.vespa.ai/pretrained-transformer-language-models-for-search-part-3)   | ⬜       |
| [記事: 検索のための事前学習済みトランスフォーマー言語モデル - パート 4](https://blog.vespa.ai/pretrained-transformer-language-models-for-search-part-4)   | ⬜        |
|[記事: 文書ランキングのためにBERTを誤用しない方法](https://bergum.medium.com/how-not-to-use-bert-for-search-ranking-4586716428d9)|⬜|
| [記事: LanceDBのIVF-PQインデックスの理解](https://lancedb.github.io/lancedb/concepts/index_ivfpq/)                                                | ⬜        |
| [記事: マルチベクトル表現のためのプーリングの効果](https://www.answer.ai/posts/colbert-pooling.html)                          | ⬜        |
|[記事: 複雑さのレベル: RAGアプリケーション](https://jxnl.github.io/blog/writing/2024/02/28/levels-of-complexity-rag-applications/)|⬜|
|[記事: RAGを体系的に改善する](https://jxnl.github.io/blog/writing/2024/05/22/systematically-improving-your-rag/)|⬜|
|[記事: LGTM@Fewを指標として使用しないでください (Better RAG)](https://jxnl.github.io/blog/writing/2024/02/05/when-to-lgtm-at-k/)|⬜|
|[記事: RAG検索のための手の届く果実](https://jxnl.github.io/blog/writing/2024/05/11/low-hanging-fruit-for-rag-search/)|⬜|
|[記事: AIエンジニアが検索について知っておくべきこと](https://softwaredoug.com/blog/2024/06/25/what-ai-engineers-need-to-know-search)|⬜|
|[記事: チャンク戦略の評価](https://research.trychroma.com/evaluating-chunking)|⬜|
|[記事: 文の埋め込み。文の埋め込み入門](https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/)|⬜|
|[記事: LambdaMARTの詳細](https://softwaredoug.com/blog/2022/01/17/lambdamart-in-depth)|⬜|
|[記事: アウトラインによるガイド付き生成](https://medium.com/canoe-intelligence-technology/guided-generation-with-outlines-c09a0c2ce9eb)|⬜|
|[記事: RAGのトリック](https://duarteocarmo.com/blog/rag-tricks-from-the-trenches)|⬜|
|[記事: 検索101](https://isaacflath.com/blog/blog_post?fpath=posts%2F2025-03-17-Retrieval101.ipynb)|⬜|
|[Arxiv: Ragas: Retrieval Augmented Generationの自動評価](https://arxiv.org/abs/2309.15217)|⬜|
| [コース: Fullstack Retrieval](https://community.fullstackretrieval.com/)                                                                        |         ⬜ |
|[コース: The RAG Flywheel](https://567-labs.github.io/systematically-improving-rag/)|⬜|
|[DeepLearning.AI: 高度なRAGアプリケーションの構築と評価](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/)|⬜|
|[DeepLearning.AI: ベクトルデータベース: 埋め込みからアプリケーションへ](https://www.deeplearning.ai/short-courses/vector-databases-embeddings-applications/)|⬜|
|[DeepLearning.AI: AIのための高度な検索](https://www.deeplearning.ai/short-courses/advanced-retrieval-for-ai/)|⬜|
|[DeepLearning.AI: プロンプト圧縮とクエリ最適化](https://www.deeplearning.ai/short-courses/prompt-compression-and-query-optimization/)|⬜|
|[DeepLearning.AI: セマンティック検索を用いた大規模言語モデル](https://www.deeplearning.ai/short-courses/large-language-models-semantic-search) `1hr`|⬜|
|[DeepLearning.AI: ベクトルデータベースを用いたアプリケーションの構築](https://www.deeplearning.ai/short-courses/building-applications-vector-databases/)|⬜|
|[DeepLearning.AI: RAGのための知識グラフ](https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/)|⬜|
|[DeepLearning.AI: LLMアプリケーションのための非構造データの前処理](https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/)|⬜|
|[DeepLearning.AI: 埋め込みモデル: アーキテクチャから実装まで](https://www.deeplearning.ai/short-courses/embedding-models-from-architecture-to-implementation)|⬜|
|[DeepLearning.AI: 検索最適化 - トークン化からベクトル量子化まで](https://www.deeplearning.ai/short-courses/retrieval-optimization-from-tokenization-to-vector-quantization/)|⬜|
|[Pinecone: 忙しいエンジニアのためのプロダクションにおけるベクトルデータベース](https://www.pinecone.io/learn/series/vector-databases-in-production-for-busy-engineers/)|⬜|
|[Pinecone: Retrieval Augmented Generation](https://www.pinecone.io/learn/series/rag/)|⬜|
|[Pinecone: Faiss: The Missing Manual](https://www.pinecone.io/learn/series/faiss/)|⬜|
|[Pinecone: セマンティック検索のための自然言語処理](https://www.pinecone.io/learn/series/nlp/)|0/13|
|[Youtube: Systematically improving RAG applications](https://youtu.be/RrDBV6odPKo?list=PLgIaq8VgndJvXkDSeReTl2u4rQMShkZ6V)|⬜|
|[Youtube: Back to Basics for RAG w/ Jo Bergum](https://www.youtube.com/watch?v=nc0BupOkrhI&list=PLgIaq8VgndJvXkDSeReTl2u4rQMShkZ6V&index=2)|⬜|
|[Youtube: Beyond the Basics of Retrieval for Augmenting Generation (w/ Ben Clavié)](https://www.youtube.com/watch?v=0nA5QG3087g&t=1287s)|⬜|
|[Youtube: RAG From Scratch](https://www.youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x) `14/14`|⬜|
|[Youtube: CMU Advanced NLP Fall 2024 (10): Retrieval and RAG](https://www.youtube.com/watch?v=KfQaYk4k9eM&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=6) `1h17m`|⬜|
|[Guidance: Token Healing](https://github.com/guidance-ai/guidance/blob/main/notebooks/tutorials/token_healing.ipynb)|⬜|
|[Youtube: What You See Is What You Search: Vision Language Models for PDF Retrieval [Jo Bergum]](https://youtu.be/qrbQUU4TrLM)|⬜|

#### エージェント工学

|教材|進捗|
|---|---|
|[Berkeley: CS294/194-196 大規模言語モデルエージェント](https://www.youtube.com/playlist?list=PLS01nW3RtgopsNLeM936V4TNSsvvVglLc) `0/14 lectures`|⬜|
|[Berkeley: 上級LLMエージェントMOOC](https://www.youtube.com/playlist?list=PLS01nW3RtgorL3AW8REU9nGkzhvtn6Egn) `0/12 lectures`|⬜|
|[記事: ツール呼び出し - GPTの汎用性の驚異を示す](https://blog.jnbrymn.com/2024/01/30/the-marvel-of-GPT-generality.html)|⬜|
|[記事: smolagentsの紹介、エージェント構築のためのシンプルなライブラリ](https://huggingface.co/blog/smolagents)|⬜|
|[記事: モデルコンテキストプロトコルが解決する問題は？](https://www.aihero.dev/what-problem-does-model-context-protocol-solve)|⬜|
|[記事: マルチエージェントを構築しないでください](https://cognition.ai/blog/dont-build-multi-agents)|⬜|
|[記事: コーディングエージェント101: 実際に物事を成し遂げる技術](https://devin.ai/agents101)|⬜|
|[記事: Claude Codeの魔法を再現するためには？](https://minusx.ai/blog/decoding-claude-code/)|⬜|
|[Anthropic: 効果的なエージェントの構築](https://www.anthropic.com/research/building-effective-agents)|⬜|
|[Anthropic: 効果的なエージェントクックブック](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents)|⬜|
|[OpenAI: アシスタントとエージェントのビルドアワー](https://vimeo.com/showcase/11333741/video/990334325)|⬜|
|[OpenAI: 関数呼び出しビルドアワー](https://vimeo.com/showcase/11333741/video/952127114)|⬜|
|[DeepLearning.AI: LangChainによる関数、ツール、エージェントの構築](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/)|⬜|
|[DeepLearning.AI: LlamaIndexを用いたエージェントRAGの構築](https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/)|⬜|
|[DeepLearning.AI: crewAIを用いたマルチAIエージェントシステム](https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/)|⬜|
|[DeepLearning.AI: Anthropicとのコンピュータ使用に向けた構築](https://www.deeplearning.ai/short-courses/building-towards-computer-use-with-anthropic/)|⬜|
|[DeepLearning.AI: LLMワークフローのためのPydantic](https://www.deeplearning.ai/short-courses/pydantic-for-llm-workflows/)|⬜|
|[DeepLearning.AI: crewAIを用いた実践的マルチAIエージェントと高度なユースケース](https://www.deeplearning.ai/short-courses/practical-multi-ai-agents-and-advanced-use-cases-with-crewai/)|⬜|
|[DeepLearning.AI: エージェントメモリとしてのLLMs](https://www.deeplearning.ai/short-courses/llms-as-operating-systems-agent-memory/)|⬜|
|[DeepLearning.AI: Amazon Bedrockによるサーバーレスエージェントワークフロー](https://www.deeplearning.ai/short-courses/serverless-agentic-workflows-with-amazon-bedrock/)|⬜|
|[DeepLearning.AI: AutoGenによるAIエージェント設計パターン](https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen/)|⬜|
|[DeepLearning.AI: LangGraphにおけるAIエージェント](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/)|⬜|
|[DeepLearning.AI: 自分自身のデータベースエージェントの構築](https://www.deeplearning.ai/short-courses/building-your-own-database-agent/)|⬜|
|[DeepLearning.AI: LLMによる関数呼び出しとデータ抽出](https://www.deeplearning.ai/short-courses/function-calling-and-data-extraction-with-llms/) `59m`|⬜|
|[DeepLearning.AI: AIエージェントの評価](https://www.deeplearning.ai/short-courses/evaluating-ai-agents/) `2h16m`|⬜|
|[DeepLearning.AI: WindsurfのAIコーディングエージェントを用いたアプリの構築](https://www.deeplearning.ai/short-courses/build-apps-with-windsurfs-ai-coding-agents/) `1h10m`|⬜|
|[DeepLearning.AI: AIブラウザエージェントの構築](https://www.deeplearning.ai/short-courses/building-ai-browser-agents)|⬜|
|[Huggingface: エージェントコース](https://huggingface.co/learn/agents-course/unit1/messages-and-special-tokens#base-models-vs-instruct-models)|Unit 1|
|[Youtube: エージェントの評価方法: Galileoによるエージェント評価の実践](https://www.youtube.com/watch?v=QvStk5G8BZw)|⬜|
|[Youtube: エージェントの応答 \| LangSmith評価 - パート 24](https://youtu.be/NbQKDfSw3gM?list=PLfaIDFEXuae0um8Fj0V4dHG37fGFU8Q5S)|⬜|
|[Youtube: シングルステップ \| LangSmith評価 - パート 25](https://youtu.be/AVPflFmRkd4?list=PLfaIDFEXuae0um8Fj0V4dHG37fGFU8Q5S)|⬜|
|[Youtube: エージェントの軌跡 \| LangSmith評価 - パート 26](https://youtu.be/pvlT056DAHs?list=PLfaIDFEXuae0um8Fj0V4dHG37fGFU8Q5S)|⬜|
|[Youtube: エージェントとアシスタントの評価: AIカンファレンス](https://www.youtube.com/watch?v=6uXWhmDRcMc)|⬜|
|[Youtube: LLMエージェントの構築、評価、反復の方法](https://youtu.be/0pnEUAwoDP0)|⬜|
|[Youtube: Mem0: スケーラブルな長期メモリを持つAIエージェントの構築](https://www.youtube.com/watch?v=EE4pvOEAjXc)|⬜|


#### コンテキストエンジニアリング

|教材|進捗|
|---|---|
|[記事: OpenAIプロンプトエンジニアリング](https://platform.openai.com/docs/guides/prompt-engineering)|⬜|
|[記事: プロンプトの基本と効果的な適用方法](https://eugeneyan.com/writing/prompting/)|⬜|
|[記事: ARC-AGI-PubでSonnet 3.5を使用して1位を獲得した方法](https://params.com/@jeremy-berman/arc-agi)|⬜|
|[Anthropicコース](https://github.com/anthropics/courses)|⬜|
|[Anthropic: Amazon BedrockコースのClaude](https://www.anthropic.com/aws-reinvent-2024/course)|⬜|
|[記事: プロンプトエンジニアリング(Liliang Weng)](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)|⬜|
|[記事: プロンプトエンジニアリング201: 高度な手法とツールキット](https://amatria.in/blog/prompt201)|⬜|
|[記事: 精度のためのLLM最適化](https://platform.openai.com/docs/guides/optimizing-llm-accuracy)|⬜|
|[記事: Primers • プロンプトエンジニアリング](https://aman.ai/primers/ai/prompt-engineering/)|⬜|
|[記事: Anyscale Endpoints: JSONモードと関数呼び出し機能](https://www.anyscale.com/blog/anyscale-endpoints-json-mode-and-function-calling-features)|⬜|
|[記事: 大規模言語モデルによるガイド付きテキスト生成](https://medium.com/productizing-language-models/guided-text-generation-with-large-language-models-d88fc3dcf4c)|⬜|
|[Anthropic: AI流暢さ](https://www.anthropic.com/ai-fluency)|⬜|
|[書籍: LLMのためのプロンプトエンジニアリング](https://www.oreilly.com/library/view/prompt-engineering-for/9781098156145/)|⬜|
|[DeepLearning.AI: o1による推論](https://www.deeplearning.ai/short-courses/reasoning-with-o1/)|⬜|
|[OpenAI: o1ビルドアワー](https://vimeo.com/showcase/11333741/video/1018737829)|⬜|
|[DeepLearning.AI: 開発者のためのChatGPTプロンプトエンジニアリング](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)|⬜|
|[DeepLearning.AI: Llama 2 & 3によるプロンプトエンジニアリング](https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/)|⬜|
|[Wandb: LLMエンジニアリング: 構造化出力](https://www.wandb.courses/courses/steering-language-models)|⬜|
|[シリーズ: プロンプトインジェクション](https://simonwillison.net/series/prompt-injection/)|⬜|
|[Youtube: プロンプトエンジニアリング概要](https://www.youtube.com/watch?v=dOxUroR57xs) `1hr4m`|⬜|
|[Youtube: プロンプトエンジニアリングワークショップ](https://youtu.be/htBTho6oEJA) `1h`|⬜|

#### 量子化
|教材|進捗|
|---|---|
|[記事: Hugging Faceによる量子化の基礎](https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/)|⬜|
|[DeepLearning.AI: 量子化の詳細](https://www.deeplearning.ai/short-courses/quantization-in-depth/)|⬜|
|[DeepLearning.AI: デバイスAI入門](https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai/)|⬜|
|[記事: 量子化のビジュアルガイド](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)|⬜|
|[記事: QLoRAと4ビット量子化](https://mccormickml.com/2024/09/14/qlora-and-4bit-quantization/)|⬜|
|[記事: インタラクティブビジュアライゼーションによるAI/LLM量子化の理解](https://smcleod.net/2024/07/understanding-ai/llm-quantisation-through-interactive-visualisations/)|⬜|
|[Youtube: CMU Advanced NLP Fall 2024 (11): 蒸留、量子化、プルーニング](https://www.youtube.com/watch?v=DvVGkj4zhVU&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=5)|⬜|
|[記事: LLM.int8()と出現特徴](https://timdettmers.com/2022/08/17/llm-int8-and-emergent-features/)|⬜|

#### 分散トレーニング

|教材|進捗|
|---|---|
|[Youtube: PyTorch FSDPとtorchaoによるOOM撃退法](https://youtu.be/UvRl4ansfCg) `49m`|⬜|
|[Youtube: PyTorchによる分散トレーニング: クラウドインフラとコードを用いた完全なチュートリアル](https://youtu.be/toUSzwR0EV8) `1h12m`|⬜|
|[Youtube: DDPの仕組み \|\| 分散データ並列](https://youtu.be/bwNtfxEDjGA)|⬜|
|[Youtube: FSDPの説明](https://youtu.be/6pVn6khIgiI)|⬜|
|[Youtube: Lecture 48: The Ultra Scale Playbook](https://youtu.be/1E8GDR8QXKw) `3h3m`|`44:24`|
|[Youtube: Invited Talk: PyTorch Distributed (DDP, RPC) - Facebook Research Scientist Shen Liによる講演](https://youtu.be/3XUG7cjte2U)|⬜|
|[Youtube: Unit 9 \| モデルトレーニングの高速化技術](https://www.youtube.com/playlist?list=PLaMu-SDt_RB403GN5DU7NYVoVmO5Vsgkh)|⬜|
|[記事: PyTorch DDPのショートガイド](https://blog.hpc.qmul.ac.uk/pytorch-ddp/)|⬜|
|[記事: PyTorchによる深層学習のスケーリング: マルチノードおよびマルチGPUトレーニングの説明 (コード付き)](https://medium.com/@ashraf.kasem.94.0/scaling-deep-learning-with-pytorch-multi-node-and-multi-gpu-training-explained-with-code-ece8f03ea59b)|⬜|
|[記事: PyTorchモデルトレーニングの加速](https://magazine.sebastianraschka.com/p/accelerating-pytorch-model-training)|⬜|
|[記事: Horovodの紹介: Uberのオープンソース分散深層学習フレームワーク for TensorFlow](https://www.uber.com/blog/horovod/)|⬜|
|[記事: PyTorchにおける分散データ並列トレーニング](https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html)|⬜|
|[記事: 複数のGPUでのトレーニング](https://d2l.ai/chapter_computational-performance/multiple-gpus.html)|⬜|


#### 並列計算

|教材|進捗|
|---|---|
|[Udacity: 並列プログラミング入門](https://www.youtube.com/playlist?list=PLAwxTw4SYaPnFKojVQrmyOGFCqHTxfdv2) `458 videos`|299/458|
|[書籍: 大規模並列プロセッサのプログラミング: 実践的アプローチ](https://www.amazon.com/Programming-Massively-Parallel-Processors-Hands/dp/0124159923)|Ch. 2|
|[Youtube: GPUパズル: ゲーム感覚で学ぶ](https://youtu.be/K4T-YwsOxrM)|⬜|

#### 推論最適化

|教材|進捗|
|---|---|
|[記事: LLMを高速化する方法](https://vgel.me/posts/faster-inference/)|⬜|
|[記事: 最速レーンへ！ 推測デコーディング - 10倍大きなモデル、追加コストなし](https://docs.titanml.co/blog/speculative-decoding-unleashed/)|⬜|
|[記事: PyTorchによる生成AIの加速 II: GPT, Fast](https://pytorch.org/blog/accelerating-generative-ai-2/)|⬜|
|[記事: マルチGPUの調和: LLM推論の効率的スケーリング](https://docs.titanml.co/blog/multi-gpu/)|⬜|
|[記事: マルチクエリアテンションが必要なすべて](https://fireworks.ai/blog/multi-query-attention-is-all-you-need)|⬜|
|[記事: トランスフォーマー推論最適化ツールセット](https://astralord.github.io/posts/transformer-inference-optimization-toolset/)|⬜|
|[DeepLearning.AI: LLMの効率的な提供](https://www.deeplearning.ai/short-courses/efficiently-serving-llms/)|⬜|
|[記事: LLM推論シリーズ: 3. KVキャッシングの説明](https://medium.com/@plienhar/llm-inference-series-3-kv-caching-unveiled-048152e461c8)|⬜|
|[記事: LLM推論シリーズ: 4. KVキャッシング、より深い洞察](https://medium.com/@plienhar/llm-inference-series-4-kv-caching-a-deeper-look-4ba9a77746c8)|⬜|
|[記事: LLM推論シリーズ: 5. モデル性能の解析](https://medium.com/@plienhar/llm-inference-series-5-dissecting-model-performance-6144aa93168f)|⬜|
|[記事: トランスフォーマー推論の算術](https://kipp.ly/transformer-inference-arithmetic/)|⬜|
|[記事: Character.AIにおけるAI推論の最適化](https://research.character.ai/optimizing-inference/)|⬜|
|[記事: Character.AIにおけるAI推論の最適化 (パートDeux)](https://research.character.ai/optimizing-ai-inference-at-character-ai-part-deux/)|⬜|
|[記事: llama.cppガイド - 任意のハードウェアでLLMsをローカルに実行する方法](https://blog.steelph0enix.dev/posts/llama-cpp-guide/)|⬜|
|[記事: AI推論のためのドメイン特化型アーキテクチャ](https://fleetwood.dev/posts/domain-specific-architectures)|⬜|
|[Youtube: SBTB 2023: Charles Frye, パラレルプロセッサ: LLMとOSカーネルの過去と未来の接続](https://www.youtube.com/watch?v=VxFtHqlMv8c)|⬜|
|[Youtube: 微調整済みモデルのデプロイ](https://youtu.be/GzEcyBykkdo) `2h28m`|⬜|
|[記事: MLモデルをCにコンパイルする楽しみ](https://bernsteinbear.com/blog/compiling-ml-models/)|⬜|
|[記事: cuBLASのような性能を持つCUDAマトリックス乗算カーネルの最適化: 作業ログ](https://siboehm.com/articles/22/CUDA-MMM)|⬜|

#### 評価とガードレール

|教材|進捗|
|---|---|
|[記事: あなたのAIプロダクトには評価が必要](https://hamel.dev/blog/posts/evals)|⬜|
|[記事: 効き目のある・ないLLM評価](https://eugeneyan.com/writing/evals/)|⬜|
|[記事: 抽象的要約のための評価と幻覚検出](https://eugeneyan.com/writing/abstractive/)|⬜|
|[記事: 人間の評価者とともにLLMをジャッジとして調整する](https://blog.ragas.io/aligning-llm-as-judge-with-human-evaluators)|⬜|
|[記事: AIアプリケーション改善のための2年間の経験から得た教訓](https://blog.ragas.io/hard-earned-lessons-from-2-years-of-improving-ai-applications)|⬜|
|[記事: 長文質問応答システムの評価](https://eugeneyan.com/writing/qa-evals/)|⬜|
|[DeepLearning.AI: LLMOpsのための自動テスト](https://www.deeplearning.ai/short-courses/automated-testing-llmops/)|⬜|
|[DeepLearning.AI: LLMアプリケーションのレッドチーミング](https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/)|⬜|
|[DeepLearning.AI: Weights and Biasesを使用した生成AIモデルの評価とデバッグ](https://www.deeplearning.ai/short-courses/evaluating-debugging-generative-ai/)|⬜|
|[DeepLearning.AI: LLMアプリケーションの品質と安全性](https://www.deeplearning.ai/short-courses/quality-safety-llm-applications/)|⬜|
|[OpenAI: 評価ビルドアワー](https://vimeo.com/showcase/11333741/video/1023317525)|⬜|
|[Youtube: LLMの計測と評価](https://youtu.be/SnbGD677_u0) `2hr33m`|⬜|
|[Youtube: LLM Eval For Text2SQL](https://youtu.be/UGmenkjGXqM?list=PLgIaq8VgndJvt-HKMHPXehyJNNXQsAVHD) `51m`|⬜|
|[Youtube: A Deep Dive on LLM Evaluation](https://youtu.be/IsZVCnViwhk?list=PLgIaq8VgndJvt-HKMHPXehyJNNXQsAVHD) `49m`|⬜|

### ファインチューニングと蒸留

|教材|進捗|
|---|---|
|[記事: トークン化の落とし穴](https://hamel.dev/notes/llm/finetuning/tokenizer_gotchas.html)|⬜|
|[記事: LoRA（Low-Rank Adaptation）を用いたLLMのファインチューニングの実践的ヒント](https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms)|⬜|
|[OpenAI: GPT-4oミニファインチューニングビルドアワー](https://vimeo.com/showcase/11333741/video/995989828)|⬜|
|[OpenAI: 蒸留ビルドアワー](https://vimeo.com/showcase/11333741/video/1029408095)|⬜|
|[記事: 合成データを生成しファインチューニングに利用する方法](https://eugeneyan.com/writing/synthetic/)|⬜|
|[DeepLearning.AI: 大規模言語モデルのファインチューニング](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)|⬜|
|[Youtube: Axolotlによるファインチューニング](https://youtu.be/mmsa4wDsiy0?list=PLgIaq8VgndJtZ_G6gxyuhHGLUy9zXV9JC) `2h10m`|⬜|
|[Youtube: LLMsのためのデータの作成、キュレーション、クリーニング](https://youtu.be/HEGaei7k0zE?list=PLgIaq8VgndJtZ_G6gxyuhHGLUy9zXV9JC) `54m`|⬜|
|[Youtube: Mistralのファインチューニングのベストプラクティス](https://youtu.be/Z_oWzTuljss?list=PLgIaq8VgndJtZ_G6gxyuhHGLUy9zXV9JC) `23m`|⬜|
|[Youtube: OpenAIモデルのファインチューニング - ベストプラクティス](https://youtu.be/Q0GSZD0Na1s?list=PLgIaq8VgndJtZ_G6gxyuhHGLUy9zXV9JC)|⬜|
|[Youtube: ファインチューニングのタイミングと理由](https://youtu.be/cPn0nHFsvFg) `1h56m`|⬜|
|[Youtube: ファインチューニングのためのナプキン数学 Pt. 1 w/Johno Whitaker](https://youtu.be/-2ebSQROew4)|⬜|
|[Youtube: ファインチューニングのためのナプキン数学 Pt. 2 w/Johno Whitaker](https://youtu.be/u2fJ6K8FjS8)|⬜|
|[Youtube: 関数呼び出しのためのLLMsのファインチューニング w/Pawel Garback](https://youtu.be/SEZ7j31u67A) `1h32m`|⬜|
|[Youtube: プロンプトからモデルへ: すでに本番環境にデプロイされたLLMsのファインチューニング w/Kyle Corbitt](https://youtu.be/4EPZZkVrXC4) `32m`|⬜|
|[Youtube: なぜファインチューニングは死んだのか w/Emmanuel Ameisen](https://youtu.be/h1c_jmk97Ss) `50m`|⬜|
|[Benchmarking QLoRA+FSDP](https://github.com/AnswerDotAI/fsdp_qlora/blob/main/benchmarks_03_2024.md)|⬜|

#### LLMシステム設計

|教材|進捗|
|---|---|
|[記事: LLMを使った構築から得た1年間の教訓](https://applied-llms.org/)|⬜|
|[記事: LLMアプリケーションのためのデータフライホイール](https://www.sh-reya.com/blog/ai-engineering-flywheel/)|⬜|
|[記事: GoDaddyにおけるLLMの実運用から得た10の教訓](https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-3-prompts-aren-t-portable-across-models)|⬜|
|[記事: 生成AIアプリとコパイロットのための新しいUXパターン](https://www.tidepool.so/blog/emerging-ux-patterns-for-generative-ai-apps-copilots)|⬜|
|[記事: 初心者のためのLLMトレーニングガイド](https://rentry.co/llm-training)|⬜|
|[記事: ChatGPTの構造化データサポートの限界を押し広げる](https://minimaxir.com/2023/12/chatgpt-structured-data/)|⬜|
|[記事: GPTed: GPT-3を用いた意味論的プローズチェック](https://vgel.me/posts/gpted-launch/)|⬜|
|[記事: LLMを心配しないでください](https://vickiboykis.com/2024/05/20/dont-worry-about-llms/)|⬜|
|[記事: 2024年のLLMに関する知見](https://simonwillison.net/2024/Dec/31/llms-in-2024/)|⬜|
|[記事: AIファーストスタートアップのためのデータ取得戦略](https://press.airstreet.com/p/data-acquisition-strategies-for-ai?utm_source=substack&utm_medium=email)|⬜|
|[記事: 合成データ生成のすべて](https://blog.ragas.io/all-about-synthetic-data-generation)|⬜|
|[DeepLearning.AI: ChatGPT APIを使ったシステム構築](https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/)|⬜|
|[DeepLearning.AI: Gradioを使った生成AIアプリケーションの構築](https://www.deeplearning.ai/short-courses/building-generative-ai-applications-with-gradio/)|⬜|
|[DeepLearning.AI: Hugging Faceによるオープンソースモデルの構築](https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/)|⬜|
|[DeepLearning.AI: Mistralの使い方](https://www.deeplearning.ai/short-courses/getting-started-with-mistral/)|⬜|
|[LLMOps: LLMを使った構築](https://www.comet.com/site/llm-course/)|⬜|
|[LLMブートキャンプ - 2023年春](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)|⬜|
|[Youtube: LLMパフォーマンスを最大化するための技術の調査](https://www.youtube.com/watch?v=ahnGLM-RC1Y)|⬜|
|[Youtube: LLMシステムとプロダクトの構築ブロック: Eugene Yan](https://www.youtube.com/watch?v=LzeC1AQ-U5o)|⬜|
|[Youtube: LLMアプリケーションの構築](https://www.youtube.com/playlist?list=PLgIaq8VgndJtrxcelEdnXbvh9fXMHeAps)|0/8|
|[記事: LLMアプリケーションのための新興アーキテクチャ](https://a16z.com/emerging-architectures-for-llm-applications/)|⬜|
|[記事: LLMベースのシステムとプロダクト構築のためのパターン](https://eugeneyan.com/writing/llm-patterns/)|⬜|
|[DeepLearning.AI: LLMOps](https://www.deeplearning.ai/short-courses/llmops/)|⬜|
|[DeepLearning.AI: Amazon BedrockによるサーバーレスLLMアプリ](https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock/)|⬜|
|[Youtube: LLM実験から最大限の成果を引き出す方法](https://youtu.be/IfcDvtl6Z1Y) `48m`|⬜|


## 技術スキル (ライブラリ/フレームワーク/ツール)

### AWS


|教材|進捗|
|---|---|
|[Udemy: AWS Certified Developer - Associate 2018](https://www.udemy.com/aws-certified-developer-associate/)|⬜|

### CSS

|教材|進捗|
|---|---|
|[Pluralsight: CSSのポジショニング](https://www.pluralsight.com/courses/css-positioning-1834)|⬜|
|[Pluralsight: CSS入門](https://www.pluralsight.com/courses/css-intro)|⬜|
|[Pluralsight: CSS: 特異性、ボックスモデル、およびベストプラクティス](https://app.pluralsight.com/interactive-courses/detail/c580b092-d94a-4ed8-8d2a-2f4d0b76f99f)|⬜|
|[Pluralsight: CSS: フレックスボックスを使用したレイアウト](https://app.pluralsight.com/interactive-courses/detail/a089d0a5-4a4c-4c4e-b883-c1bc64009619)|⬜|
|[Code School: Bootstrapの基礎](https://www.pluralsight.com/courses/code-school-blasting-off-with-bootstrap)|⬜|
|[Pluralsight: UXの基礎](https://www.pluralsight.com/courses/ux-fundamentals-2426)|⬜|
|[Codecademy: SASS入門](https://www.codecademy.com/learn/learn-sass)|⬜|
|[CSS for Javascript Developers](https://css-for-js.dev/)|⬜|
|[書籍: Refactoring UI](https://refactoringui.com/book/)|⬜|
|[Youtube: ウェブサイトをかっこよくする方法: プログラマーのための基本UX](https://www.youtube.com/watch?v=Jf0cjocP8Wk) `48m`|⬜|



### Django

|教材|進捗|
|---|---|
|[記事: Django, HTMXとAlpine.js: モダンウェブサイト、JavaScriptはオプション](https://www.saaspegasus.com/guides/modern-javascript-for-django-developers/htmx-alpine/)|⬜|

### HTML

|教材|進捗|
|---|---|
|[Codecademy: HTML入門](https://www.codecademy.com/learn/learn-html)|⬜|
|[Codecademy: ウェブサイトを作成](https://www.codecademy.com/en/courses/make-a-website)|⬜|
|[記事: 代替テキスト](https://webaim.org/techniques/alttext/)|⬜|

### Langchain

|教材|進捗|
|---|---|
|[Pinecone: LangChain AIハンドブック](https://www.pinecone.io/learn/series/langchain/)|0/11|
|[DeepLearning.AI: LLMアプリケーション開発のためのLangChain](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)|⬜|
|[DeepLearning.AI: データとの対話型チャットのためのLangChain](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)|⬜|


### JavaScript

|教材|進捗|
|---|---|
|[Udacity: ES6 - JavaScript Improved](https://www.udacity.com/course/es6-javascript-improved--ud356)|⬜|
|[Udacity: JavaScript入門](https://www.udacity.com/course/intro-to-javascript--ud803)|⬜|
|[Udacity: オブジェクト指向JS 1](https://www.udacity.com/course/object-oriented-javascript--ud015)|⬜|
|[Udacity: オブジェクト指向JS 2](https://www.udacity.com/course/object-oriented-javascript--ud711)|⬜|
|[Udemy: TypeScript入門](https://www.udemy.com/understanding-typescript/)|⬜|
|[Codecademy: JavaScript入門](https://www.codecademy.com/learn/learn-javascript)|⬜|
|[Codecademy: Jqueryトラック](https://www.codecademy.com/learn/learn-jquery)|⬜|
|[Pluralsight: Chromeデベロッパーツールの使い方](https://www.pluralsight.com/courses/chrome-developer-tools)|⬜|


### Matplotlib

|教材|進捗|
|---|---|
|[Datacamp: Seaborn入門](https://www.datacamp.com/courses/introduction-to-seaborn)|⬜|
|[Datacamp: Matplotlib入門](https://www.datacamp.com/courses/introduction-to-matplotlib)|⬜|


### MLFlow

|教材|進捗|
|---|---|
|[Datacamp: MLFlow入門](https://www.datacamp.com/courses/introduction-to-mlflow)|⬜|


### Numpy

|教材|進捗|
|---|---|
|[Youtube: Numpy配列のブロードキャスティングの説明](https://youtu.be/oG1t3qlzq14)|⬜|


### Nexxt.JS

| 教材                                                          | 進捗 |
| --------------------------------------------------------------- | -------- |
| [Docs: Next.jsでの構築を始める](https://nextjs.org/learn) |          |

### Pandas

|教材|進捗|
|---|---|
|[Datacamp: Pandasの基礎](https://www.datacamp.com/courses/pandas-foundations)|⬜|
|[Datacamp: スプレッドシートユーザーのためのPandas結合](https://www.datacamp.com/courses/pandas-joins-for-spreadsheet-users)|⬜|
|[Datacamp: Pandasを用いたデータフレームの操作](https://www.datacamp.com/courses/manipulating-dataframes-with-pandas)|⬜|
|[Datacamp: Pandasを用いたデータフレームのマージ](https://www.datacamp.com/courses/merging-dataframes-with-pandas)|⬜|
|[Datacamp: Pandasを用いたデータ操作](https://www.datacamp.com/courses/data-manipulation-with-pandas)|⬜|
|[Datacamp: Pandasを用いたPythonコードの最適化](https://www.datacamp.com/courses/optimizing-python-code-with-pandas)|⬜|
|[Datacamp: Pandasを用いたデータのストリーミングインジェクション](https://www.datacamp.com/courses/streamlined-data-ingestion-with-pandas)|⬜|
|[Datacamp: Pandasを用いたマーケティングキャンペーンの分析](https://www.datacamp.com/courses/analyzing-marketing-campaigns-with-pandas)|⬜|
|[Datacamp: Pandasを用いた警察活動の分析](https://www.datacamp.com/courses/analyzing-police-activity-with-pandas)|⬜|


### PyTorch

|教材|進捗|
|---|---|
|[記事: PyTorchの内部構造](https://blog.ezyang.com/2019/05/pytorch-internals/)|⬜|
|[記事: PyTorchを当たり前だと思わないで](https://nrehiew.github.io/blog/pytorch/)|⬜|
|[Datacamp: PyTorchによる深層学習入門](https://www.datacamp.com/courses/deep-learning-with-pytorch)|⬜|
|[Datacamp: PyTorchによる中級深層学習](https://app.datacamp.com/learn/courses/intermediate-deep-learning-with-pytorch)|⬜|
|[Datacamp: PyTorchを用いたテキストの深層学習](https://www.datacamp.com/courses/deep-learning-for-text-with-pytorch)|⬜|
|[Datacamp: PyTorchを用いた画像の深層学習](https://www.datacamp.com/courses/deep-learning-for-images-with-pytorch)|⬜|
|[Deeplizard: ニューラルネットワークプログラミング - PyTorchによる深層学習](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG)|⬜|


### ReactJS

|教材|進捗|
|---|---|
|[Codecademy: Learn ReactJS: Part I](https://www.codecademy.com/learn/react-101)|⬜|
|[Codecademy: Learn ReactJS: Part II](https://www.codecademy.com/learn/react-102)|⬜|
|[NexxtJS: React Foundations](https://nextjs.org/learn/react-foundations)|⬜|

### Spacy

|教材|進捗|
|---|---|
|[Datacamp: spaCyによる高度なNLP](https://www.datacamp.com/courses/advanced-nlp-with-spacy)|⬜|

### Tensorflow & Keras

|教材|進捗|
|---|---|
|[Datacamp: PythonにおけるTensorFlow入門](https://www.datacamp.com/courses/introduction-to-tensorflow-in-python)|⬜|
|[Datacamp: Pythonにおける深層学習](https://www.datacamp.com/courses/deep-learning-in-python)|⬜|
|[Datacamp: PythonにおけるKerasによる深層学習入門](https://www.datacamp.com/courses/deep-learning-with-keras-in-python)|⬜|
|[Datacamp: PythonにおけるKerasによる高度な深層学習](https://www.datacamp.com/courses/advanced-deep-learning-with-keras-in-python)|⬜|
|[Deeplizard: Keras - Python深層学習ニューラルネットワークAPI](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL)|⬜|
|[Udacity: 深層学習のためのTensorFlow入門](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187)|⬜|

### VSCode

|教材|進捗|
|---|---|
|[VSCode Docs: Pythonインタラクティブウィンドウ](https://code.visualstudio.com/docs/python/jupyter-support-py)|⬜|

## その他

### デザイン

|教材|進捗|
|---|---|
|[コース: 価値を視覚化する方法](https://visualizevalue.com/products/how-to-visualize-value)|⬜|
|[記事: Figmaデザインでイラストを作成する](https://help.figma.com/hc/en-us/articles/13543867954711-Create-an-illustration-in-Figma-design)|⬜|
|[シリーズ: K-12 Figmaデザインの基礎](https://www.figma.com/resource-library/k-12-design-basics/) `10 parts`|3/10|


### ファイナンス

|教材|進捗|
|---|---|
|[Coursera: 金融市場](https://www.coursera.org/learn/financial-markets-global)|⬜|



### マーケティング

|教材|進捗|
|---|---|
|[コース: 一度作って二度売る](https://visualizevalue.com/products/build-once-sell-twice-the-productization-playbook)|⬜|

### 検索エンジン最適化 (SEO)

|教材|進捗|
|---|---|
|[コース: Compound Content](https://visualizevalue.com/products/compound-content)|⬜|

### テクニカルライティング
|教材|進捗|
|---|---|
|[Google: テクニカルライティングコース](https://developers.google.com/tech-writing/overview)|⬜|
|[ハンドブック: Writing Better](https://www.julian.com/guide/write/intro)|⬜|